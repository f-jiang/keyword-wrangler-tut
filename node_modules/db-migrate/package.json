{
  "name": "db-migrate",
  "description": "Database migration framework for node.js",
  "author": {
    "name": "Jeff Kunkle"
  },
  "bin": {
    "db-migrate": "./bin/db-migrate"
  },
  "keywords": [
    "database",
    "db",
    "migrate",
    "migration",
    "sqlite",
    "mysql"
  ],
  "version": "0.9.25",
  "engines": {
    "node": ">=0.6.0"
  },
  "bugs": {
    "url": "https://github.com/kunklejr/node-db-migrate/issues"
  },
  "license": "MIT",
  "repository": {
    "type": "git",
    "url": "https://github.com/kunklejr/node-db-migrate.git"
  },
  "dependencies": {
    "async": "~0.9.0",
    "dotenv": "~0.5.1",
    "final-fs": "^1.6.0",
    "mkdirp": "~0.5.0",
    "moment": "~2.9.0",
    "mongodb": "^1.4.30",
    "mysql": "^2.10.2",
    "optimist": "~0.6.1",
    "parse-database-url": "~0.2.2",
    "pg": "^4.5.5",
    "pkginfo": "~0.3.0",
    "semver": "~4.3.3",
    "sqlite3": "^3.1.4"
  },
  "devDependencies": {
    "code": "^1.3.0",
    "db-meta": "~0.4.1",
    "lab": "^5.2.1",
    "rimraf": "~2.2.8",
    "vows": "0.8.0"
  },
  "scripts": {
    "test": "node node_modules/.bin/vows"
  },
  "readme": "[![Build Status](https://travis-ci.org/db-migrate/node-db-migrate.svg?branch=master)](https://travis-ci.org/db-migrate/node-db-migrate)\n[![Dependency Status](https://david-dm.org/db-migrate/node-db-migrate.svg)](https://david-dm.org/db-migrate/node-db-migrate)\n[![devDependency Status](https://david-dm.org/db-migrate/node-db-migrate/dev-status.svg)](https://david-dm.org/db-migrate/node-db-migrate#info=devDependencies)\n[![Documentation Status](https://readthedocs.org/projects/db-migrate/badge/?version=latest)](https://readthedocs.org/projects/db-migrate/?badge=latest)\n\n# db-migrate\n\nDatabase migration framework for node.js\n\n## Installation\n\n    $ npm install -g db-migrate\n\nDB-Migrate is now available to you via:\n\n    $ db-migrate\n\n### As local module\n\nWant to use db-migrate as local module?\n\n    $ npm install db-migrate\n\nDB-Migrate is now available to you via:\n\n    $ node node_modules/db-migrate/bin/db-migrate\n\n## Supported Databases\n\n* Mysql (https://github.com/felixge/node-mysql)\n* PostgreSQL (https://github.com/brianc/node-postgres)\n* sqlite3 (https://github.com/developmentseed/node-sqlite3)\n* Mongodb (https://github.com/mongodb/node-mongodb-native)\n\n## Usage\n\n```\nUsage: db-migrate [up|down|reset|create|db] [[dbname/]migrationName|all] [options]\n\nDown migrations are run in reverse run order, so migrationName is ignored for down migrations.\nUse the --count option to control how many down migrations are run (default is 1).\n\nOptions:\n  --env, -e                   The environment to run the migrations under.    [default: \"dev\"]\n  --migrations-dir, -m        The directory containing your migration files.  [default: \"./migrations\"]\n  --count, -c                 Max number of migrations to run.\n  --dry-run                   Prints the SQL but doesn't run it.              [boolean]\n  --verbose, -v               Verbose mode.                                   [default: false]\n  --config                    Location of the database.json file.             [default: \"./database.json\"]\n  --force-exit                Call system.exit() after migration run          [default: false]\n  --sql-file                  Create sql files for up and down.               [default: false]\n  --coffee-file               Create a coffeescript migration file            [default: false]\n  --migration-table           Set the name of the migration table.\n  --table, --migration-table                                                  [default: \"migrations\"]\n```\n\n## Creating Migrations\n\nTo create a migration, execute `db-migrate create` with a title. `node-db-migrate` will create a node module within `./migrations/` which contains the following two exports:\n\n```javascript\nexports.up = function (db, callback) {\n  callback();\n};\n\nexports.down = function (db, callback) {\n  callback();\n};\n```\n\nAll you have to do is populate these, invoking `callback()` when complete, and you are ready to migrate!\n\nFor example:\n\n    $ db-migrate create add-pets\n    $ db-migrate create add-owners\n\nThe first call creates `./migrations/20111219120000-add-pets.js`, which we can populate:\n\n```javascript\nexports.up = function (db, callback) {\n  db.createTable('pets', {\n    id: { type: 'int', primaryKey: true },\n    name: 'string'\n  }, callback);\n};\n\nexports.down = function (db, callback) {\n  db.dropTable('pets', callback);\n};\n```\n\nThe second creates `./migrations/20111219120005-add-owners.js`, which we can populate:\n\n```javascript\nexports.up = function (db, callback) {\n  db.createTable('owners', {\n    id: { type: 'int', primaryKey: true },\n    name: 'string'\n  }, callback);\n};\n\nexports.down = function (db, callback) {\n  db.dropTable('owners', callback);\n};\n```\n\nExecuting multiple statements against the database within a single migration requires a bit more care. You can either nest the migrations like:\n\n```javascript\nexports.up = function (db, callback) {\n  db.createTable('pets', {\n    id: { type: 'int', primaryKey: true },\n    name: 'string'\n  }, createOwners);\n\n  function createOwners(err) {\n    if (err) { callback(err); return; }\n    db.createTable('owners', {\n      id: { type: 'int', primaryKey: true },\n      name: 'string'\n    }, callback);\n  }\n};\n\nexports.down = function (db, callback) {\n  db.dropTable('pets', function(err) {\n    if (err) { callback(err); return; }\n    db.dropTable('owners', callback);\n  });\n};\n```\n\nor use the async library to simplify things a bit, such as:\n\n```javascript\nvar async = require('async');\n\nexports.up = function (db, callback) {\n  async.series([\n    db.createTable.bind(db, 'pets', {\n      id: { type: 'int', primaryKey: true },\n      name: 'string'\n    }),\n    db.createTable.bind(db, 'owners', {\n      id: { type: 'int', primaryKey: true },\n      name: 'string'\n    });\n  ], callback);\n};\n\nexports.down = function (db, callback) {\n  async.series([\n    db.dropTable.bind(db, 'pets'),\n    db.dropTable.bind(db, 'owners')\n  ], callback);\n};\n```\n\n### Using files for sqls\n\nIf you prefer to use sql files for your up and down statements, you can use the `--sql-file` option to automatically generate these files and the javascript code that load them.\n\nFor example:\n\n    $ db-migrate create add-people --sql-file\n\nThis call creates 3 files:\n\n```\n./migrations/20111219120000-add-people.js\n./migrations/sqls/20111219120000-add-people-up.sql\n./migrations/sqls/20111219120000-add-people-down.sql\n```\n\nThe sql files will have the following content:\n```sql\n/* Replace with your SQL commands */\n```\n\nAnd the javascript file with the following code that load these sql files:\n\n```javascript\ndbm = dbm || require('db-migrate');\nvar type = dbm.dataType;\nvar fs = require('fs');\nvar path = require('path');\n\nexports.up = function(db, callback) {\n  var filePath = path.join(__dirname + '/sqls/20111219120000-add-people-up.sql');\n  fs.readFile(filePath, {encoding: 'utf-8'}, function(err,data){\n    if (err) return console.log(err);\n    db.runSql(data, function(err) {\n      if (err) return console.log(err);\n      callback();\n    });\n  });\n};\n\nexports.down = function(db, callback) {\n  var filePath = path.join(__dirname + '/sqls/20111219120000-add-people-down.sql');\n  fs.readFile(filePath, {encoding: 'utf-8'}, function(err,data){\n    if (err) return console.log(err);\n    db.runSql(data, function(err) {\n      if (err) return console.log(err);\n      callback();\n    });\n  });\n};\n```\n\n** Making it as default **\n\nTo not need to always specify the `sql-file` option in your `db-migrate create` commands, you can set a property in your `database.json` as follows:\n\n```\n{\n    \"dev\": {\n      \"host\": \"localhost\",\n    ...\n  },\n    \"sql-file\" : true\n}\n```\n\n** Important - For MySQL users **\n\nIf you use MySQL, to be able to use multiple statements in your sql file, you have to set the property `multiple-statements: true` when creating the connection object. You can set it in your `database.json` as follows:\n\n```\n{\n    \"dev\": {\n    \"host\": \"localhost\",\n    \"user\": { \"ENV\" : \"DB_USER\" },\n    \"password\" : { \"ENV\" : \"DB_PASS\" },\n    \"database\": \"database-name\",\n    \"driver\": \"mysql\",\n    \"multipleStatements\": true\n  }\n}\n```\n\n## Running Migrations\n\nWhen first running the migrations, all will be executed in sequence. A table named `migrations` will also be created in your database to track which migrations have been applied.\n\n      $ db-migrate up\n      [INFO] Processed migration 20111219120000-add-pets\n      [INFO] Processed migration 20111219120005-add-owners\n      [INFO] Done\n\nSubsequent attempts to run these migrations will result in the following output\n\n      $ db-migrate up\n      [INFO] No migrations to run\n      [INFO] Done\n\nIf we were to create another migration using `db-migrate create`, and then execute migrations again, we would execute only those not previously executed:\n\n      $ db-migrate up\n      [INFO] Processed migration 20111220120210-add-kennels\n      [INFO] Done\n\nYou can also run migrations incrementally by specifying a date substring. The example below will run all migrations created on or before December 19, 2011:\n\n      $ db-migrate up 20111219\n      [INFO] Processed migration 20111219120000-add-pets\n      [INFO] Processed migration 20111219120005-add-owners\n      [INFO] Done\n\nYou can also run a specific number of migrations with the -c option:\n\n      $ db-migrate up -c 1\n      [INFO] Processed migration 20111219120000-add-pets\n      [INFO] Done\n\nAll of the down migrations work identically to the up migrations by substituting the word `down` for `up`.\n\n## Configuration\n\ndb-migrate supports the concept of environments. For example, you might have a dev, test, and prod environment where you need to run the migrations at different times. Environment settings are loaded from a database.json file like the one shown below:\n\n```javascript\n{\n  \"dev\": {\n    \"driver\": \"sqlite3\",\n    \"filename\": \"~/dev.db\"\n  },\n\n  \"test\": {\n    \"driver\": \"sqlite3\",\n    \"filename\": \":memory:\"\n  },\n\n  \"prod\": {\n    \"driver\": \"mysql\",\n    \"user\": \"root\",\n    \"password\": \"root\"\n  },\n\n  \"pg\": {\n    \"driver\": \"pg\",\n    \"user\": \"test\",\n    \"password\": \"test\",\n    \"host\": \"localhost\",\n    \"database\": \"mydb\",\n    \"schema\": \"my_schema\"\n  },\n\n  \"mongo\": {\n    \"driver\": \"mongodb\",\n    \"database\": \"my_db\",\n    \"host\": \"localhost\"\n  },\n\n  \"other\": \"postgres://uname:pw@server.com/dbname\"\n}\n```\n\nYou can also specify environment variables in your config file by using a special notation. Here is an example:\n```javascript\n{\n  \"prod\": {\n    \"driver\": \"mysql\",\n    \"user\": {\"ENV\": \"PRODUCTION_USERNAME\"},\n    \"password\": {\"ENV\": \"PRODUCTION_PASSWORD\"}\n  },\n}\n```\nIn this case, db-migrate will search your environment for variables\ncalled `PRODUCTION_USERNAME` and `PRODUCTION_PASSWORD`, and use those values for the corresponding configuration entry.\n\nNote that if the settings for an environment are represented by a single string that string will be parsed as a database URL.\n\nYou can pass the -e or --env option to db-migrate to select the environment you want to run migrations against. The --config option can be used to specify the path to your database.json file if it's not in the current working directory.\n\n    db-migrate up --config config/database.json -e prod\n\nThe above will run all migrations that haven't yet been run in the prod environment, grabbing the settings from config/database.json.\n\nAlternatively, you can specify a DATABASE_URL\nenvironment variable that will be used in place of the configuration\nfile settings. This is helpful for use with Heroku.\n\n## Multiple migration scopes\n\nYou can have multiple migration scopes, which are subfolders within your migrations folder. A scope gets called like the following:\n\n    $ db-migrate up:myScope\n\n#### Scope Configuration\n\nYou can also configure the scope to specify a sub configuration. Currently you can only define database and schema within this config.\n\nThis config file is used to tell db-migrate to switch to the `database` or\n`schema`. Databases is used for most databases, except **postgres**\nwhich needs the schema variable.\n\nIt's currently also not possible to switch the database over this config with **postgres**.\n\n```json\n{\n  \"database\": \"test\",\n  \"schema\": \"test\"\n}\n```\n## Defaults\n\n## Generic Datatypes\n\nThere is currently a small list of generic Datatypes you can use, to make your\nmigrations more database independent.\n\nFind the list of supported types [here](https://github.com/kunklejr/node-db-migrate/blob/master/lib/data_type.js).\n\n## Migrations API - SQL\n\nBelow are examples of all the different migrations supported by db-migrate. Please note that not all migrations are supported by all databases. For example, SQLite does not support dropping columns.\n\n### createTable(tableName, columnSpec, callback)\n\nCreates a new table with the specified columns.\n\n__Arguments__\n\n* tableName - the name of the table to create\n* columnSpec - a hash of column definitions\n* callback(err) - callback that will be invoked after table creation\n\n__Examples__\n\n```javascript\n// with no table options\nexports.up = function (db, callback) {\n  db.createTable('pets', {\n    id: { type: 'int', primaryKey: true, autoIncrement: true },\n    name: 'string'  // shorthand notation\n  }, callback);\n}\n\n// with table options\nexports.up = function (db, callback) {\n  db.createTable('pets', {\n    columns: {\n      id: { type: 'int', primaryKey: true, autoIncrement: true },\n      name: 'string'  // shorthand notation\n    },\n    ifNotExists: true\n  }, callback);\n}\n```\n\n__Column Specs__\n\nThe following options are available on column specs\n\n* type - the column data type. Supported types can be found in lib/data_type.js\n* length - the column data length, where supported\n* primaryKey - true to set the column as a primary key. Compound primary keys are supported by setting the `primaryKey` option to true on multiple columns\n* autoIncrement - true to mark the column as auto incrementing\n* notNull - true to mark the column as non-nullable, omit it archive database default behavior and false to mark explicitly as nullable\n* unique - true to add unique constraint to the column\n* defaultValue - set the column default value\n* foreignKey - set a foreign key to the column\n\n__Column ForeignKey Spec Examples__\n\n**Note:** Currently only supported together with mysql!\n\n```javascript\nexports.up = function(db, callback) {\n\n  //automatic mapping, the mapping key resolves to the column\n  db.createTable( 'product_variant',\n  {\n      id:\n      {\n        type: 'int',\n        unsigned: true,\n        notNull: true,\n        primaryKey: true,\n        autoIncrement: true,\n        length: 10\n      },\n      product_id:\n      {\n        type: 'int',\n        unsigned: true,\n        length: 10,\n        notNull: true,\n        foreignKey: {\n          name: 'product_variant_product_id_fk',\n          table: 'product',\n          rules: {\n            onDelete: 'CASCADE',\n            onUpdate: 'RESTRICT'\n          },\n          mapping: 'id'\n        }\n      },\n  }, callback );\n};\n\nexports.up = function(db, callback) {\n\n  //explicit mapping\n  db.createTable( 'product_variant',\n  {\n    id:\n    {\n      type: 'int',\n      unsigned: true,\n      notNull: true,\n      primaryKey: true,\n      autoIncrement: true,\n      length: 10\n    },\n    product_id:\n    {\n      type: 'int',\n      unsigned: true,\n      length: 10,\n      notNull: true,\n      foreignKey: {\n        name: 'product_variant_product_id_fk',\n        table: 'product',\n        rules: {\n          onDelete: 'CASCADE',\n          onUpdate: 'RESTRICT'\n        },\n        mapping: {\n          product_id: 'id'\n        }\n      }\n    },\n  }, callback );\n};\n```\n\n### dropTable(tableName, [options,] callback)\n\nDrop a database table\n\n__Arguments__\n\n* tableName - name of the table to drop\n* options - table options\n* callback(err) - callback that will be invoked after dropping the table\n\n__Table Options__\n\n* ifExists - Only drop the table if it already exists\n\n### renameTable(tableName, newTableName, callback)\n\nRename a database table\n\n__Arguments__\n\n* tableName - existing table name\n* options - new table name\n* callback(err) - callback that will be invoked after renaming the table\n\n### addColumn(tableName, columnName, columnSpec, callback)\n\nAdd a column to a database table\n\n__Arguments__\n\n* tableName - name of table to add a column to\n* columnName - name of the column to add\n* columnSpec - a hash of column definitions\n* callback(err) - callback that will be invoked after adding the column\n\nColumn spec is the same as that described in createTable\n\n### removeColumn(tableName, columnName, callback)\n\nRemove a column from an existing database table\n\n* tableName - name of table to remove a column from\n* columnName - name of the column to remove\n* callback(err) - callback that will be invoked after removing the column\n\n### renameColumn(tableName, oldColumnName, newColumnName, callback)\n\nRename a column\n\n__Arguments__\n\n* tableName - table containing column to rename\n* oldColumnName - existing column name\n* newColumnName - new name of the column\n* callback(err) - callback that will be invoked after renaming the column\n\n### changeColumn(tableName, columnName, columnSpec, callback)\n\nChange the definition of a column\n\n__Arguments__\n\n* tableName - table containing column to change\n* columnName - existing column name\n* columnSpec - a hash containing the column spec\n* callback(err) - callback that will be invoked after changing the column\n\n### addIndex(tableName, indexName, columns, [unique], callback)\n\nAdd an index\n\n__Arguments__\n\n* tableName - table to add the index too\n* indexName - the name of the index\n* columns - an array of column names contained in the index\n* unique - whether the index is unique (optional, default false)\n* callback(err) - callback that will be invoked after adding the index\n\n### addForeignKey\n\nAdds a foreign Key\n\n__Arguments__\n\n* tableName - table on which the foreign key gets applied\n* referencedTableName - table where the referenced key is located\n* keyName - name of the foreign key\n* fieldMapping - mapping of the foreign key to referenced key\n* rules - ondelete, onupdate constraints\n* callback(err) - callback that will be invoked after adding the foreign key\n\n__Example__\n\n```javascript\nexports.up = function (db, callback)\n{\n  db.addForeignKey('module_user', 'modules', 'module_user_module_id_foreign',\n  {\n    'module_id': 'id'\n  },\n  {\n    onDelete: 'CASCADE',\n    onUpdate: 'RESTRICT'\n  }, callback);\n};\n```\n\n### removeForeignKey\n\n__Arguments__\n\n* tableName - table in which the foreign key should be deleted\n* keyName - the name of the foreign key\n* options - object of options, see below\n* callback - callback that will be invoked once the foreign key was deleted\n\n__Options__\n\n* dropIndex (default: false) - deletes the index with the same name as the foreign key\n\n__Examples__\n\n```javascript\n//without options object\nexports.down = function (db, callback)\n{\n  db.removeForeignKey('module_user', 'module_user_module_id_foreign', callback);\n};\n\n//with options object\nexports.down = function (db, callback)\n{\n  db.removeForeignKey('module_user', 'module_user_module_id_foreign',\n  {\n    dropIndex: true,\n  }, callback);\n};\n```\n\n### insert(tableName, columnNameArray, valueArray, callback)\n\nInsert an item into a given column\n\n__Arguments__\n\n* tableName - table to insert the item into\n* columnNameArray - the array existing column names for each item being inserted\n* valueArray - the array of values to be inserted into the associated column\n* callback(err) - callback that will be invoked once the insert has been completed.\n\n### removeIndex([tableName], indexName, callback)\n\nRemove an index\n\n__Arguments__\n\n* tableName - name of the table that has the index (Required for mySql)\n* indexName - the name of the index\n* callback(err) - callback that will be invoked after removing the index\n\n### runSql(sql, [params,] callback)\n\nRun arbitrary SQL\n\n__Arguments__\n\n* sql - the SQL query string, possibly with ? replacement parameters\n* params - zero or more ? replacement parameters\n* callback(err) - callback that will be invoked after executing the SQL\n\n### all(sql, [params,] callback)\n\nExecute a select statement\n\n__Arguments__\n\n* sql - the SQL query string, possibly with ? replacement parameters\n* params - zero or more ? replacement parameters\n* callback(err, results) - callback that will be invoked after executing the SQL\n\n## Migrations API - NoSQL\n\nBelow are examples of all the different migrations supported by db-migrate for NoSQL databases.\n\n### createCollection(collectionName, callback)\n\nCreates a new collection.\n\n__Arguments__\n\n* collectionName - the name of the collection to create\n* callback(err) - callback that will be invoked after table creation\n\n__Examples__\n\n```javascript\nexports.up = function (db, callback) {\n  db.createCollection('pets', callback);\n}\n```\n\n### dropCollection(collectionName, callback)\n\nDrop a database collection\n\n__Arguments__\n\n* collectionName - name of the collection to drop\n* callback(err) - callback that will be invoked after dropping the collection\n\n### renameCollection(collectionName, newCollectionName, callback)\n\nRename a database table\n\n__Arguments__\n\n* collectionName - existing collection name\n* newCollectionName - new collection name\n* callback(err) - callback that will be invoked after renaming the collection\n\n### addIndex(collectionName, indexName, columns, unique, callback)\n\nAdd an index\n\n__Arguments__\n\n* collectionName - collection to add the index too\n* indexName - the name of the index\n* columns - an array of column names contained in the index\n* unique - whether the index is unique\n* callback(err) - callback that will be invoked after adding the index\n\n### removeIndex(collectionName, indexName, callback)\n\nRemove an index\n\n__Arguments__\n\n* collectionName - name of the collection that has the index\n* indexName - the name of the index\n* callback(err) - callback that will be invoked after removing the index\n\n### insert(collectionName, toInsert, callback)\n\nInsert an item into a given collection\n\n__Arguments__\n\n* collectionName - collection to insert the item into\n* toInsert - an object or array of objects to be inserted into the associated collection\n* callback(err) - callback that will be invoked once the insert has been completed.\n\n## Development\n\nThe following command runs the vows tests.\n\n```bash\nnpm test\n```\n\nRunning the tests requires a one-time setup of the **MySQL**, **MongoDB** and **Postgres** databases.\n\n```bash\nmysql -u root -e \"CREATE DATABASE db_migrate_test;\"\ncreatedb db_migrate_test\n```\n\nYou will also need to copy `test/db.config.example.json` to `test/db.config.json`\nand adjust appropriate to setup configuration for your database instances.\n\n## License\n\n(The MIT License)\n\nCopyright (c) 2013 Jeff Kunkle\n\nPermission is hereby granted, free of charge, to any person obtaining\na copy of this software and associated documentation files (the\n\"Software\"), to deal in the Software without restriction, including\nwithout limitation the rights to use, copy, modify, merge, publish,\ndistribute, sublicense, and/or sell copies of the Software, and to\npermit persons to whom the Software is furnished to do so, subject to\nthe following conditions:\n\nThe above copyright notice and this permission notice shall be\nincluded in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\nMERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\nNONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\nLIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\nOF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\nWITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n",
  "readmeFilename": "README.md",
  "_id": "db-migrate@0.9.25",
  "dist": {
    "shasum": "a1ad874311558f2a25112855059de17310bba371"
  },
  "_from": "db-migrate@",
  "_resolved": "https://registry.npmjs.org/db-migrate/-/db-migrate-0.9.25.tgz"
}
